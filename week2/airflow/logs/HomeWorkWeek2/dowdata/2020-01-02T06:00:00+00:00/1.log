[2022-01-30 13:02:29,958] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-01-30 13:02:30,002] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-01-30 13:02:30,002] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 13:02:30,002] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 13:02:30,002] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 13:02:30,059] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2020-01-02 06:00:00+00:00
[2022-01-30 13:02:30,072] {standard_task_runner.py:52} INFO - Started process 2618 to run task
[2022-01-30 13:02:30,080] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2020-01-02T06:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmp2vy8q3jr', '--error-file', '/tmp/tmp7gdwlcu0']
[2022-01-30 13:02:30,083] {standard_task_runner.py:77} INFO - Job 127: Subtask dowdata
[2022-01-30 13:02:30,338] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [running]> on host 4b3b8c5e49b1
[2022-01-30 13:02:30,559] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 13:02:30,666] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2020-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-02T06:00:00+00:00
[2022-01-30 13:02:30,668] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 13:02:30,669] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv > /opt/***output_2020-01.csv']
[2022-01-30 13:02:30,693] {subprocess.py:85} INFO - Output:
[2022-01-30 13:05:19,141] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 13:05:19,389] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20200102T060000, start_date=20220130T130229, end_date=20220130T130519
[2022-01-30 13:05:19,524] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 13:05:19,643] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-30 14:50:49,690] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-01-30 14:50:49,742] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-01-30 14:50:49,742] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 14:50:49,743] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 14:50:49,743] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 14:50:49,789] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2020-01-02 06:00:00+00:00
[2022-01-30 14:50:49,798] {standard_task_runner.py:52} INFO - Started process 895 to run task
[2022-01-30 14:50:49,810] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2020-01-02T06:00:00+00:00', '--job-id', '213', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpd6egmd__', '--error-file', '/tmp/tmpf9mfwk1p']
[2022-01-30 14:50:49,812] {standard_task_runner.py:77} INFO - Job 213: Subtask dowdata
[2022-01-30 14:50:50,176] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [running]> on host 785c0c715caa
[2022-01-30 14:50:50,408] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 14:50:50,548] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2020-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-02T06:00:00+00:00
[2022-01-30 14:50:50,551] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 14:50:50,554] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv > /opt/***output_2020-01.csv']
[2022-01-30 14:50:50,577] {subprocess.py:85} INFO - Output:
[2022-01-30 14:52:28,094] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 14:52:28,330] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20200102T060000, start_date=20220130T145049, end_date=20220130T145228
[2022-01-30 14:52:28,475] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 14:52:28,984] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-02-19 01:21:28,927] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-02-19 01:21:28,967] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-02-19 01:21:28,968] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 01:21:28,968] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 01:21:28,976] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 01:21:29,017] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2020-01-02 06:00:00+00:00
[2022-02-19 01:21:29,024] {standard_task_runner.py:52} INFO - Started process 2464 to run task
[2022-02-19 01:21:29,029] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2020-01-02T06:00:00+00:00', '--job-id', '562', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmp94yvr22q', '--error-file', '/tmp/tmpf2tfo8h5']
[2022-02-19 01:21:29,031] {standard_task_runner.py:77} INFO - Job 562: Subtask dowdata
[2022-02-19 01:21:29,302] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [running]> on host 312f1fe573aa
[2022-02-19 01:21:29,511] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 01:21:29,644] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2020-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-02T06:00:00+00:00
[2022-02-19 01:21:29,647] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 01:21:29,648] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv > /opt/***output_2020-01.csv']
[2022-02-19 01:21:29,675] {subprocess.py:85} INFO - Output:
[2022-02-19 01:22:49,473] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 01:22:49,554] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20200102T060000, start_date=20220219T012128, end_date=20220219T012249
[2022-02-19 01:22:49,634] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 01:22:49,920] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-02-19 11:25:08,569] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-02-19 11:25:08,616] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-02-19 11:25:08,616] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 11:25:08,617] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 11:25:08,617] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 11:25:08,660] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2020-01-02 06:00:00+00:00
[2022-02-19 11:25:08,668] {standard_task_runner.py:52} INFO - Started process 3481 to run task
[2022-02-19 11:25:08,675] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2020-01-02T06:00:00+00:00', '--job-id', '932', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpt0n5fbvg', '--error-file', '/tmp/tmpwakqe4f4']
[2022-02-19 11:25:08,688] {standard_task_runner.py:77} INFO - Job 932: Subtask dowdata
[2022-02-19 11:25:08,857] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [running]> on host f81f14254480
[2022-02-19 11:25:09,027] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 11:25:09,088] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2020-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-02T06:00:00+00:00
[2022-02-19 11:25:09,090] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 11:25:09,092] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv > /opt/***output_2020-01.csv']
[2022-02-19 11:25:09,116] {subprocess.py:85} INFO - Output:
[2022-02-19 11:26:04,464] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 11:26:04,949] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20200102T060000, start_date=20220219T112508, end_date=20220219T112604
[2022-02-19 11:26:05,024] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 11:26:05,172] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-20 00:08:41,963] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-02-20 00:08:42,012] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [queued]>
[2022-02-20 00:08:42,012] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-20 00:08:42,013] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-20 00:08:42,013] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-20 00:08:42,059] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2020-01-02 06:00:00+00:00
[2022-02-20 00:08:42,066] {standard_task_runner.py:52} INFO - Started process 23462 to run task
[2022-02-20 00:08:42,072] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2020-01-02T06:00:00+00:00', '--job-id', '1096', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpuf3vprnd', '--error-file', '/tmp/tmpyeb7x87v']
[2022-02-20 00:08:42,074] {standard_task_runner.py:77} INFO - Job 1096: Subtask dowdata
[2022-02-20 00:08:42,261] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2020-01-02T06:00:00+00:00 [running]> on host d9977d7db207
[2022-02-20 00:08:42,402] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-20 00:08:42,453] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2020-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2020-01-02T06:00:00+00:00
[2022-02-20 00:08:42,457] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-20 00:08:42,459] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2020-01.csv > /opt/***yellow_2020-01.csv']
[2022-02-20 00:08:42,478] {subprocess.py:85} INFO - Output:
[2022-02-20 00:09:47,443] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-20 00:09:47,523] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20200102T060000, start_date=20220220T000841, end_date=20220220T000947
[2022-02-20 00:09:47,644] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-20 00:09:47,841] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
