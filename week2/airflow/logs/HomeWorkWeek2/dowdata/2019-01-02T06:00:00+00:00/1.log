[2022-01-30 12:50:17,787] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-01-30 12:50:17,855] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-01-30 12:50:17,856] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 12:50:17,856] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 12:50:17,857] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 12:50:17,924] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-01-02 06:00:00+00:00
[2022-01-30 12:50:17,946] {standard_task_runner.py:52} INFO - Started process 1997 to run task
[2022-01-30 12:50:17,959] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-01-02T06:00:00+00:00', '--job-id', '105', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmp2efa2s64', '--error-file', '/tmp/tmpdtw8l8pf']
[2022-01-30 12:50:17,961] {standard_task_runner.py:77} INFO - Job 105: Subtask dowdata
[2022-01-30 12:50:18,123] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [running]> on host 4b3b8c5e49b1
[2022-01-30 12:50:18,257] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 12:50:18,315] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-02T06:00:00+00:00
[2022-01-30 12:50:18,318] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 12:50:18,319] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv > /opt/***output_2019-01.csv']
[2022-01-30 12:50:18,339] {subprocess.py:85} INFO - Output:
[2022-01-30 12:52:44,894] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 12:52:45,080] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190102T060000, start_date=20220130T125017, end_date=20220130T125245
[2022-01-30 12:52:45,208] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 12:52:45,324] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-30 14:38:27,746] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-01-30 14:38:27,857] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-01-30 14:38:27,857] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 14:38:27,857] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 14:38:27,858] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 14:38:27,981] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-01-02 06:00:00+00:00
[2022-01-30 14:38:27,990] {standard_task_runner.py:52} INFO - Started process 171 to run task
[2022-01-30 14:38:27,999] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-01-02T06:00:00+00:00', '--job-id', '180', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpmoxehicp', '--error-file', '/tmp/tmp67qcf2pl']
[2022-01-30 14:38:28,000] {standard_task_runner.py:77} INFO - Job 180: Subtask dowdata
[2022-01-30 14:38:28,157] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [running]> on host 785c0c715caa
[2022-01-30 14:38:28,235] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 14:38:28,335] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-02T06:00:00+00:00
[2022-01-30 14:38:28,337] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 14:38:28,337] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv > /opt/***output_2019-01.csv']
[2022-01-30 14:38:28,357] {subprocess.py:85} INFO - Output:
[2022-01-30 14:39:58,391] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 14:39:58,467] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190102T060000, start_date=20220130T143827, end_date=20220130T143958
[2022-01-30 14:39:58,533] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 14:39:58,669] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-30 15:53:30,389] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-01-30 15:53:30,445] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-01-30 15:53:30,446] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 15:53:30,446] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 15:53:30,446] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 15:53:30,500] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-01-02 06:00:00+00:00
[2022-01-30 15:53:30,512] {standard_task_runner.py:52} INFO - Started process 241 to run task
[2022-01-30 15:53:30,550] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-01-02T06:00:00+00:00', '--job-id', '289', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmp3m4c4ecm', '--error-file', '/tmp/tmp3o6flss0']
[2022-01-30 15:53:30,563] {standard_task_runner.py:77} INFO - Job 289: Subtask dowdata
[2022-01-30 15:53:31,029] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [running]> on host 76a6ca5a1f6b
[2022-01-30 15:53:31,221] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 15:53:31,285] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-02T06:00:00+00:00
[2022-01-30 15:53:31,295] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 15:53:31,298] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv > /opt/***output_2019-01.csv']
[2022-01-30 15:53:31,333] {subprocess.py:85} INFO - Output:
[2022-01-30 15:55:37,792] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 15:55:37,891] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190102T060000, start_date=20220130T155330, end_date=20220130T155537
[2022-01-30 15:55:38,002] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 15:55:38,194] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-19 00:35:43,828] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-02-19 00:35:43,877] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-02-19 00:35:43,878] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:35:43,878] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 00:35:43,878] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:35:43,930] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-01-02 06:00:00+00:00
[2022-02-19 00:35:43,936] {standard_task_runner.py:52} INFO - Started process 253 to run task
[2022-02-19 00:35:43,943] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-01-02T06:00:00+00:00', '--job-id', '514', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmplxdaa4g6', '--error-file', '/tmp/tmpbq9n9k85']
[2022-02-19 00:35:43,946] {standard_task_runner.py:77} INFO - Job 514: Subtask dowdata
[2022-02-19 00:35:44,098] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [running]> on host 312f1fe573aa
[2022-02-19 00:35:44,200] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 00:35:44,247] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-02T06:00:00+00:00
[2022-02-19 00:35:44,250] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 00:35:44,251] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv > /opt/***output_2019-01.csv']
[2022-02-19 00:35:44,268] {subprocess.py:85} INFO - Output:
[2022-02-19 00:37:10,579] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 00:37:10,725] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190102T060000, start_date=20220219T003543, end_date=20220219T003710
[2022-02-19 00:37:10,861] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 00:37:10,991] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-19 10:40:17,123] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-02-19 10:40:17,187] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-02-19 10:40:17,188] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 10:40:17,188] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 10:40:17,194] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 10:40:17,243] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-01-02 06:00:00+00:00
[2022-02-19 10:40:17,250] {standard_task_runner.py:52} INFO - Started process 1358 to run task
[2022-02-19 10:40:17,256] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-01-02T06:00:00+00:00', '--job-id', '884', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmphlvaucrr', '--error-file', '/tmp/tmph_qkuxsz']
[2022-02-19 10:40:17,258] {standard_task_runner.py:77} INFO - Job 884: Subtask dowdata
[2022-02-19 10:40:17,405] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [running]> on host f81f14254480
[2022-02-19 10:40:17,519] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 10:40:17,571] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-02T06:00:00+00:00
[2022-02-19 10:40:17,573] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 10:40:17,575] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv > /opt/***output_2019-01.csv']
[2022-02-19 10:40:17,593] {subprocess.py:85} INFO - Output:
[2022-02-19 10:41:47,297] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 10:41:47,412] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190102T060000, start_date=20220219T104017, end_date=20220219T104147
[2022-02-19 10:41:47,504] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 10:41:47,697] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-19 23:24:43,185] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-02-19 23:24:43,235] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [queued]>
[2022-02-19 23:24:43,236] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 23:24:43,238] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 23:24:43,238] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 23:24:43,284] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-01-02 06:00:00+00:00
[2022-02-19 23:24:43,295] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-01-02T06:00:00+00:00', '--job-id', '1049', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpm2fxm1n1', '--error-file', '/tmp/tmpp99rq_6b']
[2022-02-19 23:24:43,298] {standard_task_runner.py:77} INFO - Job 1049: Subtask dowdata
[2022-02-19 23:24:43,290] {standard_task_runner.py:52} INFO - Started process 21373 to run task
[2022-02-19 23:24:43,430] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-01-02T06:00:00+00:00 [running]> on host d9977d7db207
[2022-02-19 23:24:43,544] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 23:24:43,624] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-01-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-02T06:00:00+00:00
[2022-02-19 23:24:43,626] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 23:24:43,628] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-01.csv > /opt/***yellow_2019-01.csv']
[2022-02-19 23:24:43,644] {subprocess.py:85} INFO - Output:
[2022-02-19 23:26:28,372] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 23:26:28,480] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190102T060000, start_date=20220219T232443, end_date=20220219T232628
[2022-02-19 23:26:28,578] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 23:26:28,751] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
