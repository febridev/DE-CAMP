[2022-01-30 12:55:37,433] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-01-30 12:55:37,497] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-01-30 12:55:37,498] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 12:55:37,498] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 12:55:37,498] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 12:55:37,555] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-05-02 06:00:00+00:00
[2022-01-30 12:55:37,567] {standard_task_runner.py:52} INFO - Started process 2255 to run task
[2022-01-30 12:55:37,574] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-05-02T06:00:00+00:00', '--job-id', '111', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpzsl6t_pa', '--error-file', '/tmp/tmptc93h6e0']
[2022-01-30 12:55:37,576] {standard_task_runner.py:77} INFO - Job 111: Subtask dowdata
[2022-01-30 12:55:37,963] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [running]> on host 4b3b8c5e49b1
[2022-01-30 12:55:38,288] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 12:55:38,458] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-05-02T06:00:00+00:00
[2022-01-30 12:55:38,461] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 12:55:38,463] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv > /opt/***output_2019-05.csv']
[2022-01-30 12:55:38,529] {subprocess.py:85} INFO - Output:
[2022-01-30 12:59:05,555] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 12:59:05,831] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190502T060000, start_date=20220130T125537, end_date=20220130T125905
[2022-01-30 12:59:05,926] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 12:59:06,036] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-30 14:43:09,623] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-01-30 14:43:09,671] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-01-30 14:43:09,672] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 14:43:09,672] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 14:43:09,672] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 14:43:09,718] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-05-02 06:00:00+00:00
[2022-01-30 14:43:09,726] {standard_task_runner.py:52} INFO - Started process 446 to run task
[2022-01-30 14:43:09,737] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-05-02T06:00:00+00:00', '--job-id', '190', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpohc6ow7n', '--error-file', '/tmp/tmp58oblgmg']
[2022-01-30 14:43:09,740] {standard_task_runner.py:77} INFO - Job 190: Subtask dowdata
[2022-01-30 14:43:09,999] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [running]> on host 785c0c715caa
[2022-01-30 14:43:10,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 14:43:10,251] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-05-02T06:00:00+00:00
[2022-01-30 14:43:10,253] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 14:43:10,255] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv > /opt/***output_2019-05.csv']
[2022-01-30 14:43:10,277] {subprocess.py:85} INFO - Output:
[2022-01-30 14:45:16,330] {subprocess.py:93} INFO - Command exited with return code 0
[2022-01-30 14:45:16,682] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190502T060000, start_date=20220130T144309, end_date=20220130T144516
[2022-01-30 14:45:16,819] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-30 14:45:16,998] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-30 16:06:08,609] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-01-30 16:06:08,680] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-01-30 16:06:08,681] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 16:06:08,681] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-01-30 16:06:08,681] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-30 16:06:08,725] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-05-02 06:00:00+00:00
[2022-01-30 16:06:08,737] {standard_task_runner.py:52} INFO - Started process 852 to run task
[2022-01-30 16:06:08,752] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-05-02T06:00:00+00:00', '--job-id', '302', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmptsyt1w61', '--error-file', '/tmp/tmphde51ayr']
[2022-01-30 16:06:08,754] {standard_task_runner.py:77} INFO - Job 302: Subtask dowdata
[2022-01-30 16:06:09,021] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [running]> on host 76a6ca5a1f6b
[2022-01-30 16:06:09,221] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-30 16:06:09,329] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-05-02T06:00:00+00:00
[2022-01-30 16:06:09,332] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-01-30 16:06:09,333] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv > /opt/***output_2019-05.csv']
[2022-01-30 16:06:09,363] {subprocess.py:85} INFO - Output:
[2022-02-19 00:47:20,586] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-02-19 00:47:20,626] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-02-19 00:47:20,626] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:47:20,626] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 00:47:20,627] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 00:47:20,677] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-05-02 06:00:00+00:00
[2022-02-19 00:47:20,684] {standard_task_runner.py:52} INFO - Started process 813 to run task
[2022-02-19 00:47:20,691] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-05-02T06:00:00+00:00', '--job-id', '528', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmp31ffncft', '--error-file', '/tmp/tmpatfekdwy']
[2022-02-19 00:47:20,693] {standard_task_runner.py:77} INFO - Job 528: Subtask dowdata
[2022-02-19 00:47:20,882] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [running]> on host 312f1fe573aa
[2022-02-19 00:47:21,016] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 00:47:21,090] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-05-02T06:00:00+00:00
[2022-02-19 00:47:21,093] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 00:47:21,094] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv > /opt/***output_2019-05.csv']
[2022-02-19 00:47:21,113] {subprocess.py:85} INFO - Output:
[2022-02-19 00:49:42,471] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 00:49:42,755] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190502T060000, start_date=20220219T004720, end_date=20220219T004942
[2022-02-19 00:49:42,822] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 00:49:42,977] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-19 10:51:42,236] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-02-19 10:51:42,293] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-02-19 10:51:42,293] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 10:51:42,293] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 10:51:42,294] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 10:51:42,342] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-05-02 06:00:00+00:00
[2022-02-19 10:51:42,348] {standard_task_runner.py:52} INFO - Started process 1900 to run task
[2022-02-19 10:51:42,360] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-05-02T06:00:00+00:00', '--job-id', '898', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmp8ylm5fay', '--error-file', '/tmp/tmp2vrqaqna']
[2022-02-19 10:51:42,362] {standard_task_runner.py:77} INFO - Job 898: Subtask dowdata
[2022-02-19 10:51:42,655] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [running]> on host f81f14254480
[2022-02-19 10:51:42,899] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 10:51:42,977] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-05-02T06:00:00+00:00
[2022-02-19 10:51:42,980] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 10:51:42,981] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv > /opt/***output_2019-05.csv']
[2022-02-19 10:51:43,008] {subprocess.py:85} INFO - Output:
[2022-02-19 10:54:17,110] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 10:54:17,524] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190502T060000, start_date=20220219T105142, end_date=20220219T105417
[2022-02-19 10:54:17,640] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 10:54:17,887] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-02-19 23:36:38,964] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-02-19 23:36:39,002] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [queued]>
[2022-02-19 23:36:39,003] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 23:36:39,003] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-02-19 23:36:39,003] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-02-19 23:36:39,050] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): dowdata> on 2019-05-02 06:00:00+00:00
[2022-02-19 23:36:39,058] {standard_task_runner.py:52} INFO - Started process 21932 to run task
[2022-02-19 23:36:39,065] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'HomeWorkWeek2', 'dowdata', 'scheduled__2019-05-02T06:00:00+00:00', '--job-id', '1062', '--raw', '--subdir', 'DAGS_FOLDER/dag_questions1.py', '--cfg-path', '/tmp/tmpw9s1zxzn', '--error-file', '/tmp/tmpp1osatz5']
[2022-02-19 23:36:39,067] {standard_task_runner.py:77} INFO - Job 1062: Subtask dowdata
[2022-02-19 23:36:39,259] {logging_mixin.py:109} INFO - Running <TaskInstance: HomeWorkWeek2.dowdata scheduled__2019-05-02T06:00:00+00:00 [running]> on host d9977d7db207
[2022-02-19 23:36:39,449] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-02-19 23:36:39,535] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=HomeWorkWeek2
AIRFLOW_CTX_TASK_ID=dowdata
AIRFLOW_CTX_EXECUTION_DATE=2019-05-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-05-02T06:00:00+00:00
[2022-02-19 23:36:39,540] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-02-19 23:36:39,543] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv > /opt/***yellow_2019-05.csv']
[2022-02-19 23:36:39,569] {subprocess.py:85} INFO - Output:
[2022-02-19 23:38:40,546] {subprocess.py:93} INFO - Command exited with return code 0
[2022-02-19 23:38:40,616] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=HomeWorkWeek2, task_id=dowdata, execution_date=20190502T060000, start_date=20220219T233638, end_date=20220219T233840
[2022-02-19 23:38:40,716] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-02-19 23:38:40,846] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
